{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import h5py\n","import numpy as np\n","import cv2\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D,MaxPool2D,Activation, Dropout, Flatten, Dense, BatchNormalization\n","from keras.optimizers import RMSprop\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["img=cv2.imread('../input/mosaicps2/dataset/0/0_1.jpg')\n"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["train_dir='../input/mosaicps2/dataset'"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["trainDataGen = ImageDataGenerator(rescale = 1.0/255)"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 36576 images belonging to 36 classes.\n"]}],"source":["trainGenerator = trainDataGen.flow_from_directory(\n","train_dir,\n","target_size = (28,28),\n","batch_size = 36,\n","color_mode = \"grayscale\",\n","class_mode = \"categorical\")"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu', input_shape = (28,28,1)))\n","model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","\n","#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 #activation ='relu'))\n","#model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 #activation ='relu'))\n","#model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","#model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n","                 activation ='relu'))\n","model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation = \"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(36, activation = \"softmax\"))"]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_8 (Conv2D)            (None, 28, 28, 32)        832       \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 28, 28, 32)        25632     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","conv2d_11 (Conv2D)           (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 3136)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 512)               1606144   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 36)                18468     \n","=================================================================\n","Total params: 1,706,500\n","Trainable params: 1,706,500\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[],"source":["optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","365/365 [==============================] - 10s 25ms/step - loss: 1.7102 - accuracy: 0.5392\n","Epoch 2/10\n","365/365 [==============================] - 9s 25ms/step - loss: 0.3861 - accuracy: 0.8922\n","Epoch 3/10\n","365/365 [==============================] - 10s 26ms/step - loss: 0.2618 - accuracy: 0.9205\n","Epoch 4/10\n","365/365 [==============================] - 9s 25ms/step - loss: 0.2315 - accuracy: 0.9341\n","Epoch 5/10\n","365/365 [==============================] - 10s 29ms/step - loss: 0.2106 - accuracy: 0.9373\n","Epoch 6/10\n","365/365 [==============================] - 10s 27ms/step - loss: 0.1868 - accuracy: 0.9485\n","Epoch 7/10\n","365/365 [==============================] - 9s 26ms/step - loss: 0.1639 - accuracy: 0.9518\n","Epoch 8/10\n","365/365 [==============================] - 9s 25ms/step - loss: 0.1677 - accuracy: 0.9523\n","Epoch 9/10\n","365/365 [==============================] - 9s 26ms/step - loss: 0.1577 - accuracy: 0.9558\n","Epoch 10/10\n","365/365 [==============================] - 9s 26ms/step - loss: 0.1418 - accuracy: 0.9564\n"]}],"source":["history=model.fit_generator(trainGenerator,verbose=1,epochs=10,steps_per_epoch=(1016*36) // 100)"]},{"cell_type":"code","execution_count":31,"metadata":{"trusted":true},"outputs":[],"source":["model.save(\"Model_plate.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"}}},"nbformat":4,"nbformat_minor":4}
